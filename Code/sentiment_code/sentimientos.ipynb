{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Universidad\\Legislacion\\Scrapy threads\\Analisis de sentimientos\\sentiment_analysis\\sentiment\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|| 23.9k/23.9k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|| 3.78M/3.78M [00:01<00:00, 2.67MB/s]\n",
      "Downloading data: 100%|| 901k/901k [00:00<00:00, 1.37MB/s]\n",
      "Downloading data: 100%|| 167k/167k [00:00<00:00, 281kB/s]\n",
      "Generating train split: 100%|| 45615/45615 [00:00<00:00, 709426.77 examples/s]\n",
      "Generating test split: 100%|| 12284/12284 [00:00<00:00, 645633.32 examples/s]\n",
      "Generating validation split: 100%|| 2000/2000 [00:00<?, ? examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('tweet_eval', 'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n",
      "validation\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "max_len = 200\n",
    "batch_size = 16\n",
    "dataset_path = 'C:/Users/andre/Downloads/datos_threads.csv'\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             post_link user_name  \\\n",
      "0    https://www.threads.net/@farandulaalrojovivo/p...      Hilo   \n",
      "1    https://www.threads.net/@achirasgiron/post/C9f...      Hilo   \n",
      "2    https://www.threads.net/@el.azuayo/post/C9Km1W...      Hilo   \n",
      "3    https://www.threads.net/@ecuainm1/post/C9KjVbf...      Hilo   \n",
      "4    https://www.threads.net/@jaircarrion_/post/C9B...      Hilo   \n",
      "..                                                 ...       ...   \n",
      "295  https://www.threads.net/@pajaropolitico/post/C...      Hilo   \n",
      "296  https://www.threads.net/@radiodinamicaecu/post...      Hilo   \n",
      "297  https://www.threads.net/@radiodinamicaecu/post...      Hilo   \n",
      "298  https://www.threads.net/@mmcuesta/post/C1_935I...      Hilo   \n",
      "299  https://www.threads.net/@tctelevision/post/C0M...      Hilo   \n",
      "\n",
      "                                     profile_link                 post_date  \\\n",
      "0    https://www.threads.net/@farandulaalrojovivo  2024-07-17T00:03:48.000Z   \n",
      "1           https://www.threads.net/@achirasgiron  2024-07-16T15:56:00.000Z   \n",
      "2              https://www.threads.net/@el.azuayo  2024-07-08T14:52:16.000Z   \n",
      "3               https://www.threads.net/@ecuainm1  2024-07-08T14:21:57.000Z   \n",
      "4           https://www.threads.net/@jaircarrion_  2024-07-05T03:12:38.000Z   \n",
      "..                                            ...                       ...   \n",
      "295       https://www.threads.net/@pajaropolitico  2024-05-17T19:09:00.000Z   \n",
      "296     https://www.threads.net/@radiodinamicaecu  2024-04-28T15:48:40.000Z   \n",
      "297     https://www.threads.net/@radiodinamicaecu  2024-04-17T19:10:09.000Z   \n",
      "298             https://www.threads.net/@mmcuesta  2024-01-12T12:02:10.000Z   \n",
      "299         https://www.threads.net/@tctelevision  2023-11-28T17:27:38.000Z   \n",
      "\n",
      "                                           description  \\\n",
      "0    #ALROJOVIVOEC答答答答答答 \\nEl presidente Daniel No...   \n",
      "1    Vicepresidente Ver贸nica Abad asegura que no re...   \n",
      "2    #ECUADOR|| La vicepresidenta Ver贸nica Abad se...   \n",
      "3    硷URGENTEElla (Ver贸nica Abad) se va a salir s...   \n",
      "4    Enner Valencia y Daniel Noboa. \\nLo peor que t...   \n",
      "..                                                 ...   \n",
      "295  El presidente de Ecuador, Daniel Noboa  Azin, ...   \n",
      "296  グ佛La esposa del presidente Daniel Noboa y pr...   \n",
      "297  サ Cuatro dias de descanso El Gobierno de Ec...   \n",
      "298  El Presidente  Daniel Noboa envi贸 anoche a la ...   \n",
      "299  Daniel Noboa envi贸 a la Asamblea el primer Pro...   \n",
      "\n",
      "                                            multimedia  \n",
      "0                                                  NaN  \n",
      "1                                                  NaN  \n",
      "2                                                  NaN  \n",
      "3    https://scontent.cdninstagram.com/o1/v/t16/f2/...  \n",
      "4                                                  NaN  \n",
      "..                                                 ...  \n",
      "295                                                NaN  \n",
      "296                                                NaN  \n",
      "297                                                NaN  \n",
      "298                                                NaN  \n",
      "299  https://scontent.cdninstagram.com/v/t51.29350-...  \n",
      "\n",
      "[300 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_path, sep=';')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pre_trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase:  Estoy comiendo en familia\n",
      "Tokens:  ['Estoy', 'comiendo', 'en', 'familia']\n",
      "Tokens num茅ricos:  [2040, 15139, 1036, 2268]\n"
     ]
    }
   ],
   "source": [
    "sample_txt = 'Estoy comiendo en familia'\n",
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print('Frase: ', sample_txt)\n",
    "print('Tokens: ', tokens)\n",
    "print('Tokens num茅ricos: ', tokens_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Universidad\\Legislacion\\Scrapy threads\\Analisis de sentimientos\\sentiment_analysis\\sentiment\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "    sample_txt,\n",
    "    max_length=10,\n",
    "    truncation=True,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
